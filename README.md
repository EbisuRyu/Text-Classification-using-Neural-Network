# Text Classification using Neural Network (Torchtext)


In this endeavor, I focused on crafting a Sentiment Text Classification system tailored specifically for the Vietnamese language, employing a straightforward neural network approach. My primary goal was to demonstrate the application of Deep Learning techniques in addressing basic tasks. With this objective in mind, I committed myself to meticulously designing and training the model from the ground up.

**ğŸ“Author:**

- **Github:** [EbisuRyu](https://github.com/DSRoAI) ğŸ”—
- **Email:** nhhlong2004@gmail.com ğŸ“§
- **Facebook:** [Long Hoang](https://www.facebook.com/hoanglong.roai/) ğŸ‘¤
- **LinkedIn:** [Long Nguyen Huu Hoang](https://www.linkedin.com/in/long-nguy%E1%BB%85n-h%E1%BB%AFu-ho%C3%A0ng-023870287/) ğŸ’¼

> **If you find this repository helpful, please consider giving it a â­ï¸!**

## Table of Contents
* [Setup](#setup)
  * [Environment](#environment)
  * [Pretrained Models and Vocabulary](#pretrained-models-and-vocabulary)
* [Usage](#usage)
  * [Training](#training)
  * [Inference](#inference)
* [Data](#data)

## Setup
### Environment
Using Miniconda/Anaconda: Below is the command line to create a Conda environment using a YAML file.

```
cd path_to_repo
conda env create -f environment.yml
conda activate project_env
```

### Pretrained Model
## Pretrained Models and Vocabulary

All pretrained models are located in the `model` folder 

While pretrained vocabularies can be found in the `vocab` folder.

## Usage
### Training
Before starting training you can either choose a configuration out of available ones or create your own inside a single file `script/config.py`. The available parameters to customize, sorted by categories, are:

- **DIRECTORIES** 

  - ğŸ“ **TRAIN_DIR**: Training data directory
  - ğŸ“ **VALID_DIR**: Validation data directory
  - ğŸ“ **TEST_DIR**: Test data directory

- **PATHS**

  - ğŸ’¾ **MODEL_SAVE_PATH**: Path to save trained models
  - ğŸ’¾ **VOCAB_SAVE_PATH**: Path to save vocabulary

- **MODEL PARAMETERS**

  - ğŸ“Š **VOCAB_SIZE**: Vocabulary size
  - ğŸ’¾ **SAVE_EPOCH**: Save model after every n epochs
  - ğŸ“ **LOG_INTERVAL**: Log interval for printing training progress
  - ğŸ“¦ **BATCH_SIZE**: Batch size for training
  - ğŸ“ˆ **LR**: Learning rate

- **MODEL ARCHITECTURE**

  - ğŸŒ **EMBED_DIM**: Embedding dimension
  - ğŸ” **HIDDEN_DIM**: Hidden dimension
  - ğŸ”¢ **NUM_CLASS**: Number of classes (Negative and Positive)

- **DEVICE**

  - ğŸ’» **DEVICE**: Device to run the model on (e.g., 'cpu', 'cuda')


Once you decide on the configuration edit the config name in main.py and do:
```
$ cd script
$ python main.py
```

### Inference
To facilitate inference, I've developed a straightforward application using Streamlit, which operates directly within your browser. Prior to using the app, ensure that you've either trained your models or downloaded pretrained ones. The application automatically searches the model directory for checkpoints of both the model and the vocabulary.
```
$ cd script
$ streamlit run inference_app.py
```
![alt text](other/image.png)

## Data

### Description

This dataset contains Vietnamese text data classified into two sentiment classes: "Negative" and "Positive." It is tailored for sentiment analysis or classification tasks in the Vietnamese language. The dataset is structured into two main folders:

- **data_train**: This folder contains the training data used for model development.

- **data_test**: This folder comprises the testing data utilized to evaluate model performance.

Each data instance within the dataset is labeled with its corresponding sentiment class, enabling the application of supervised learning techniques for sentiment analysis or classification tasks.

The data originates from blogs hosted on the website: [StreetCodeVN](https://streetcodevn.com/).
#### Folder Structure
```
|__ data_train
|     |
|     |__ train
|     |     |__ pos
|     |     |__ neg
|     |
|     |__ test
|           |__ pos
|           |__ neg
|
|__ data_test
      |
      |__ test
            |__ pos
            |__ neg
```

### Data Instance

#### Positive:
```
Xe_Ä‘áº©y bÃ¡n cÆ¡m_chiÃªn náº±m ngay Ä‘áº§u Ä‘Æ°á»ng vÃ o khu dÃ¢n_cÆ° metro , cháº¡y tá»« ngoÃ i vÃ´ lÃ  xe thá»©_hai nhÃ© . MÃ¬nh hay mua cÆ¡m cá»§a chá»‹ nÃ y láº¯m , cÆ¡m_chiÃªn má»m , nÃ³ng_Äƒn chung vá»›i trá»©ng chiÃªn , láº¡p_xÆ°á»Ÿng , thá»‹t heo vÃ  chÃ  bÃ´ng nÃªn vá»«a Äƒn láº¯m mÃ  cÃ³ thÃªm dÆ°a_leo vÃ  cÃ _chua nÃªn Äƒn_khÃ´ng ngÃ¡n , Äƒn xong há»£p cÆ¡m lÃ  bao no Ä‘áº¿n trÆ°a . GiÃ¡ chá»§ cÃ³ 10/1 há»™p Ã  . Buá»•i_sÃ¡ng ráº¥t Ä‘Ã´ng ngÆ°á»i ghÃ© mua , vÃ¬ bÃ¡n vá»«a ngon vá»«a ráº» láº¡i Äƒn ráº¥t no . Tuy Ä‘Ã´ng nhÆ°ng chá»‹ lÃ m nhanh láº¯m mÃ  nÃ³i_chuyá»‡n vá»›i khÃ¡ch cÅ©ng vui_váº» lá»‹ch_sá»± ná»¯a nÃªn láº§n nÃ o Ä‘i ngang buá»•i_sÃ¡ng lÃ  ghÃ© mua hoÃ i Ã  .
```

#### Negative:
```
Mua cÃ³ má»—i Bingsu tháº­p_cáº©m 45k mÃ  mÃ¬nh f Ä‘á»£i hÆ¡n 20 ' . Há»i láº¡i thÃ¬ nv tl cÃ³ r nhg báº£o chá» thÃªm 15 ' ná»¯a " tá»¥i e lm liá»n " .
MÃ¬nh k biáº¿t cÃ³ ngon k nhg cÅ©ng muá»‘n Äƒn thá»­ . Thiáº¿t_nghÄ© nv quÃ¡n nÃªn xem_láº¡i cÃ¡ch pv vÃ  nc vs khÃ¡ch .

```